{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import xlsxwriter\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import logging\n",
    "import os\n",
    "import threading\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "def open_web():\n",
    "    try:\n",
    "        url = \"http://www.researcherid.com/ViewProfileSearch.action\"\n",
    "        driver = webdriver.Chrome(\"C:\\\\Python34\\\\chromedriver.exe\")    \n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.find_element_by_id('country').find_elements_by_tag_name(\"option\")[220].click() #點擊頁面上\"Country/Region\"的\"Taiwan\"的項目\n",
    "\n",
    "        driver.find_element_by_id('submitImage').click() #點擊頁面上\"Submit\"的項目\n",
    "\n",
    "        driver.find_element_by_id('resultsPerPage').find_elements_by_tag_name(\"option\")[2].click() #修改頁面上Results的顯示筆數\n",
    "\n",
    "        return driver\n",
    "    except:\n",
    "        driver.close()  \n",
    "        print('網頁錯誤，等候重新開啟')        \n",
    "        return None\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def write_excel(sheet,p0,p1,p2,p3,p4,p5,p6,p7):\n",
    "    try:\n",
    "        if sheet == Work_sheet: \n",
    "            global Work_row\n",
    "            Work_sheet.write(Work_row, 0, p0)\n",
    "            Work_sheet.set_column(Work_row, 0, len(p0))\n",
    "\n",
    "            Work_sheet.write(Work_row, 1, p1)\n",
    "            Work_sheet.set_column(Work_row, 1, len(p1))\n",
    "\n",
    "            Work_sheet.write(Work_row, 2, p2)\n",
    "            Work_sheet.set_column(Work_row, 2, len(p2))\n",
    "\n",
    "            Work_sheet.write(Work_row, 3, p3)\n",
    "            Work_sheet.set_column(Work_row, 3, len(p3))\n",
    "\n",
    "            Work_sheet.write(Work_row, 4, p4)\n",
    "            if len(p4) == 0:\n",
    "                Work_sheet.set_column(Work_row, 4, 20) \n",
    "            else:\n",
    "                Work_sheet.set_column(Work_row, 4, len(p4))\n",
    "\n",
    "            Work_sheet.write(Work_row, 5, p5)\n",
    "            if len(p5) == 0:\n",
    "                Work_sheet.set_column(Work_row, 5, 20) \n",
    "            else:\n",
    "                Work_sheet.set_column(Work_row, 5, len(p5)) \n",
    "\n",
    "            Work_sheet.write(Work_row, 6, p6)\n",
    "            if len(p6) == 0:\n",
    "                Work_sheet.set_column(Work_row, 6, 20) \n",
    "            else:\n",
    "                Work_sheet.set_column(Work_row, 6, len(p6))       \n",
    "\n",
    "            Work_row = Work_row + 1        \n",
    "\n",
    "        elif sheet == Institution_sheet: \n",
    "            global Institution_row\n",
    "            Institution_sheet.write(Institution_row, 0, p0)        \n",
    "            Institution_sheet.set_column(Institution_row, 0, len(p0))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 1, p1)\n",
    "            Institution_sheet.set_column(Institution_row, 1, len(p1))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 2, p2)\n",
    "            if len(p2) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 2, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 2, len(p2))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 3, p3)\n",
    "            if len(p3) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 3, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 3, len(p3))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 4, p4)\n",
    "            if len(p4) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 4, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 4, len(p4))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 5, p5)\n",
    "            if len(p5) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 5, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 5, len(p5))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 6, p6)\n",
    "            if len(p6) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 6, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 6, len(p6))\n",
    "\n",
    "            Institution_sheet.write(Institution_row, 7, p7)\n",
    "            if len(p7) == 0:\n",
    "                Institution_sheet.set_column(Institution_row, 7, 20) \n",
    "            else:\n",
    "                Institution_sheet.set_column(Institution_row, 7, len(p7))    \n",
    "\n",
    "            Institution_row = Institution_row + 1        \n",
    "\n",
    "        elif sheet == Info_sheet: \n",
    "            global Info_row\n",
    "            Info_sheet.write(Info_row, 0, p0)\n",
    "            Info_sheet.set_column(Info_row, 0, 20)\n",
    "\n",
    "            Info_sheet.write(Info_row, 1, p1)\n",
    "            Info_sheet.set_column(Info_row, 1, len(p1))\n",
    "\n",
    "            Info_sheet.write(Info_row, 2, p2)\n",
    "            if len(p2) == 0:\n",
    "                Info_sheet.set_column(Info_row, 2, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 2, len(p2))\n",
    "\n",
    "            Info_sheet.write(Info_row, 3, p3)\n",
    "            if len(p3) == 0:\n",
    "                Info_sheet.set_column(Info_row, 3, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 3, len(p3))\n",
    "\n",
    "            Info_sheet.write(Info_row, 4, p4)\n",
    "            if len(p4) == 0:\n",
    "                Info_sheet.set_column(Info_row, 4, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 4, len(p4))\n",
    "\n",
    "            Info_sheet.write(Info_row, 5, p5)\n",
    "            if len(p5) == 0:\n",
    "                Info_sheet.set_column(Info_row, 5, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 5, len(p5))\n",
    "\n",
    "            Info_sheet.write(Info_row, 6, p6)\n",
    "            if len(p6) == 0:\n",
    "                Info_sheet.set_column(Info_row, 6, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 6, len(p6))     \n",
    "\n",
    "            Info_sheet.write(Info_row, 7, p7)\n",
    "            if len(p7) == 0:\n",
    "                Info_sheet.set_column(Info_row, 7, 20) \n",
    "            else:\n",
    "                Info_sheet.set_column(Info_row, 7, len(p7))      \n",
    "\n",
    "            Info_row = Info_row + 1\n",
    "    except Exception as e:\n",
    "        logger.info('Excel寫入失敗')\n",
    "        traceback = sys.exc_info()[2]\n",
    "        logger.error(sys.exc_info())\n",
    "        logger.error(traceback.tb_lineno)\n",
    "        logger.error(e)\n",
    "#------------------------------------------------------------------------------------------\n",
    "def Info_Crawl(RI,work_driver):\n",
    "    try:\n",
    "        Name =''\n",
    "        Other_Names = ''\n",
    "        ORCID = ''\n",
    "        Email = ''\n",
    "        My_URLs = ''\n",
    "        Keywords =''\n",
    "        Subject = ''\n",
    "\n",
    "        Name = work_driver.find_element_by_xpath('//div[@class=\"profileName\"]').text\n",
    "        profileTable_key = work_driver.find_elements_by_xpath('//table[@class=\"profileTable\"]//tr//td[@class=\"profileFieldLabel\"]') \n",
    "        profileTable_value = work_driver.find_elements_by_xpath('//table[@class=\"profileTable\"]//tr//td[@class=\"profileDataCells\"]') \n",
    "        \n",
    "        profileTableInst_key = work_driver.find_elements_by_xpath('//table[@class=\"profileTableInst\"]//tr//td[@class=\"profileFieldLabel\"]')\n",
    "        profileTableInst_value = work_driver.find_elements_by_xpath('//table[@class=\"profileTableInst\"]//tr//td[@class=\"profileDataCells\"]')\n",
    "        \n",
    "        profileTableDesc_key = work_driver.find_elements_by_xpath('//table[@class=\"profileTableDesc\"]//tr//td[@class=\"profileFieldLabel\"]')\n",
    "        profileTableDesc_value = work_driver.find_elements_by_xpath('//table[@class=\"profileTableDesc\"]//tr//td[@class=\"profileDataCells\"]//a')\n",
    "        \n",
    "#         logger.info(profileTable_value)\n",
    "        key =[]\n",
    "        value = []\n",
    "        for index, item in enumerate(profileTable_key):\n",
    "            title = item.text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\").replace(\":\",\"\")\n",
    "            key.append(title)\n",
    "            if title == 'ORCID':\n",
    "                value.append(profileTable_value[index].find_element_by_xpath('a').text)\n",
    "            elif title == 'E-mail':\n",
    "                value.append(profileTable_value[index].find_element_by_xpath('label').text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\"))\n",
    "            else:\n",
    "                value.append(profileTable_value[index].text) \n",
    "            \n",
    "        for index, item in enumerate(profileTableInst_key):\n",
    "            key.append(item.text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\").replace(\":\",\"\"))\n",
    "            if  len(profileTableInst_value)>index:\n",
    "                value.append(profileTableInst_value[index].text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\"))  \n",
    "            else:\n",
    "                value.append('')\n",
    "        \n",
    "        for index, item in enumerate(profileTableDesc_key):\n",
    "            key.append(item.text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\").replace(\":\",\"\"))\n",
    "            if  len(profileTableDesc_value)>index:\n",
    "                value.append(profileTableDesc_value[0].text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\"))\n",
    "            else:\n",
    "                value.append('')              \n",
    "\n",
    "\n",
    "        Info_item = {}\n",
    "        \n",
    "        Info_item['RI'] = RI\n",
    "        Info_item['Name'] = Name\n",
    "        Info_item['Other_Names'] = ''\n",
    "        Info_item['ORCID'] = ''\n",
    "        Info_item['E-mail'] = ''\n",
    "        Info_item['My URLs'] = ''\n",
    "        Info_item['Keywords'] = ''\n",
    "        Info_item['Subject'] = ''\n",
    "        \n",
    "#         logger.info(Info_item)\n",
    "        \n",
    "        for index,item in enumerate (key):\n",
    "            Info_item[item] = value[index]\n",
    "\n",
    "        Info_item_list.append(Info_item)\n",
    "    \n",
    "#         logger.info(Info_item)\n",
    "        write_excel_thread = threading.Thread(write_excel(Info_sheet,\n",
    "                                                RI,\n",
    "                                                Name,\n",
    "                                                Info_item['Other_Names'],\n",
    "                                                Info_item['ORCID'],\n",
    "                                                Info_item['E-mail'],\n",
    "                                                Info_item['My URLs'],\n",
    "                                                Info_item['Keywords'],\n",
    "                                                Info_item['Subject']))\n",
    "        write_excel_thread.start()         \n",
    "           \n",
    "        \n",
    "        logger.info('Info_item抓取完成')\n",
    "    except Exception as e:\n",
    "        logger.info('Info_item抓取失敗')\n",
    "        traceback = sys.exc_info()[2]\n",
    "        logger.error(sys.exc_info())\n",
    "        logger.error(traceback.tb_lineno)\n",
    "        logger.error(e)\n",
    "#------------------------------------------------------------------------------------------\n",
    "def Institution_Crawl(RI,work_driver):\n",
    "    try:\n",
    "        href = work_driver.find_element_by_xpath('//table[@class=\"profileTableInst\"]//tbody//tr//td//a').get_attribute('href').replace(\"javascript:getInstitutionDetails('\",\"\").replace(\"')\",\"\")\n",
    "        url = 'http://www.researcherid.com/DisplayPublicProfileInstitutions.action?rid=' + href\n",
    "        data = requests.get(url)\n",
    "        soup = BeautifulSoup(data.text,'html.parser')\n",
    "        \n",
    "        Primary_Institution =''\n",
    "        Joint_Affiliation =''\n",
    "        Past_Institution_Name =''\n",
    "\n",
    "        SubOrg_Dept_1 = ''\n",
    "        SubOrg_Dept_2 = ''\n",
    "        SubOrg_Dept_3 = ''\n",
    "\n",
    "        Role_1 =''\n",
    "        Role_2 =''\n",
    "        Role_3 =''\n",
    "\n",
    "        Start_Date_1 = ''\n",
    "        Start_Date_2 = ''\n",
    "        Start_Date_3 = ''\n",
    "        End_Date = ''\n",
    "\n",
    "        profileFieldLabelLeft = soup.find_all('td',{'class':'profileFieldLabelLeft'})\n",
    "        if profileFieldLabelLeft != []:\n",
    "            Past_Institution_Name = profileFieldLabelLeft[0].text.replace(\"  \",\"\")\n",
    "            if len(profileFieldLabelLeft) > 1:\n",
    "                SubOrg_Dept_3 = profileFieldLabelLeft[1].text.replace(\"  \",\"\")\n",
    "            if len(profileFieldLabelLeft) > 3:\n",
    "                Role_3 = profileFieldLabelLeft[3].text.replace(\"  \",\"\")\n",
    "            if len(profileFieldLabelLeft) > 4:\n",
    "                Start_Date_3 = profileFieldLabelLeft[4].text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "            if len(profileFieldLabelLeft) > 5:\n",
    "                End_Date = profileFieldLabelLeft[5].text.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "\n",
    "        profileDataCells = soup.find_all('td',{'class':'profileDataCells'})\n",
    "        if profileDataCells != []:\n",
    "            if len(profileDataCells) > 4:\n",
    "                SubOrg_Dept_1 = profileDataCells[4].text.replace(\"  \",\"\")\n",
    "            if len(profileDataCells) > 9:\n",
    "                SubOrg_Dept_2 = profileDataCells[9].text.replace(\"  \",\"\")\n",
    "         \n",
    "        affiliationName = soup.find('label',{'id':'researcher_affiliationName'})\n",
    "        if affiliationName != None:\n",
    "            Joint_Affiliation = affiliationName.text.replace(\"\\n\",\"\").replace(\"  \",\"\")\n",
    "            \n",
    "        role_description = soup.find('label',{'id':'researcher_role_description'})\n",
    "        if role_description != None:\n",
    "            Role_1 = role_description.text\n",
    "\n",
    "        researcher_institution = soup.find('label',{'id':'researcher_institution'})\n",
    "        if researcher_institution != None:\n",
    "            Primary_Institution = soup.find('label',{'id':'researcher_institution'}).text    \n",
    "\n",
    "        role_description = soup.find('label',{'id':'researcher_affiliationAddress_role_description'})\n",
    "        if role_description != None:\n",
    "            Role_2 = role_description.text.replace(\"  \",\"\")\n",
    "\n",
    "        address_startDate = soup.find('label',{'id':'researcher_address_startDate'})\n",
    "        if address_startDate!= None:\n",
    "            Start_Date_1 = address_startDate.text.replace(\"  \",\"\")\n",
    "\n",
    "        affiliationAddress_startDate = soup.find('label',{'id':'researcher_affiliationAddress_startDate'})    \n",
    "        if affiliationAddress_startDate!= None:\n",
    "            Start_Date_2 = affiliationAddress_startDate.text.replace(\"  \",\"\")\n",
    "\n",
    "        Institution_item={}\n",
    "        Institution_item['RI'] = RI\n",
    "        Institution_item['Primary_Institution'] = Primary_Institution\n",
    "        Institution_item['Joint_Affiliation'] = Joint_Affiliation\n",
    "        Institution_item['Past_Institution_Name'] = Past_Institution_Name\n",
    "        Institution_item['SubOrg_Dept'] = SubOrg_Dept_1.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Role'] = Role_1.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Start_Date'] = Start_Date_1.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['End_Date'] =''        \n",
    "        Institution_item_list.append(Institution_item)\n",
    "#         logger.error(Institution_item)\n",
    "        \n",
    "#         write_excel(Institution_sheet,\n",
    "#                     RI,\n",
    "#                     Primary_Institution,\n",
    "#                     Joint_Affiliation,\n",
    "#                     Past_Institution_Name,\n",
    "#                     Institution_item['SubOrg_Dept'],\n",
    "#                     Institution_item['Role'],\n",
    "#                     Institution_item['Start_Date'],\n",
    "#                     Institution_item['End_Date']) \n",
    "        write_excel_thread_0 = threading.Thread(write_excel(Institution_sheet,\n",
    "                                                            RI,\n",
    "                                                            Primary_Institution,\n",
    "                                                            Joint_Affiliation,\n",
    "                                                            Past_Institution_Name,\n",
    "                                                            Institution_item['SubOrg_Dept'],\n",
    "                                                            Institution_item['Role'],\n",
    "                                                            Institution_item['Start_Date'],\n",
    "                                                            Institution_item['End_Date']))\n",
    "        write_excel_thread_0.start()\n",
    "\n",
    "        \n",
    "        Institution_item['SubOrg_Dept'] = SubOrg_Dept_2.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Role'] = Role_2.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Start_Date'] = Start_Date_2.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item_list.append(Institution_item)\n",
    "#         logger.error(Institution_item)\n",
    "        \n",
    "        write_excel_thread_1 = threading.Thread(write_excel(Institution_sheet,\n",
    "                                                            RI,\n",
    "                                                            Primary_Institution,\n",
    "                                                            Joint_Affiliation,\n",
    "                                                            Past_Institution_Name,\n",
    "                                                            Institution_item['SubOrg_Dept'],\n",
    "                                                            Institution_item['Role'],\n",
    "                                                            Institution_item['Start_Date'],\n",
    "                                                            Institution_item['End_Date']))\n",
    "        write_excel_thread_1.start()   \n",
    "\n",
    "        Institution_item['SubOrg_Dept'] = SubOrg_Dept_3.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Role'] = Role_3.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['Start_Date'] = Start_Date_3.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item['End_Date'] = End_Date.replace(\"  \",\"\").replace(\"\\r\\n\",\"\")\n",
    "        Institution_item_list.append(Institution_item)   \n",
    "#         logger.error(Institution_item)\n",
    "        \n",
    "        write_excel_thread_2 = threading.Thread(write_excel(Institution_sheet,\n",
    "                                                            RI,\n",
    "                                                            Primary_Institution,\n",
    "                                                            Joint_Affiliation,\n",
    "                                                            Past_Institution_Name,\n",
    "                                                            Institution_item['SubOrg_Dept'],\n",
    "                                                            Institution_item['Role'],\n",
    "                                                            Institution_item['Start_Date'],\n",
    "                                                            Institution_item['End_Date']))\n",
    "        write_excel_thread_2.start()\n",
    "\n",
    "        logger.info('Institution_item 抓取完成')\n",
    "    except Exception as e:\n",
    "        logger.info('Institution_item 抓取失敗')\n",
    "        logger.error(e)\n",
    "        traceback = sys.exc_info()[2]\n",
    "        logger.error(sys.exc_info())\n",
    "        logger.error(traceback.tb_lineno)\n",
    "        logger.error(e)\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def Work_Search(url,work_driver):\n",
    "    logger.info(url)  \n",
    "    \n",
    "    update_per_data_action = work_driver.find_elements_by_xpath('//select [@id=\"resultsPerPage\"]//option[@value=\"50\"]')\n",
    "    if update_per_data_action != []:\n",
    "        update_per_data_action[0].click() #修改頁面上Results的顯示筆數 \n",
    "        \n",
    "    RI = work_driver.find_elements_by_xpath('//td[@class=\"profileDataCells\"]')[0].text  #RID欄位資料\n",
    "\n",
    "    Crawls_threads = threading.Thread(target = Crawls(RI,work_driver), name='Works_Crawl')\n",
    "    Institution_Crawl_thread = threading.Thread(target=Institution_Crawl(RI,work_driver), name='Institution_Crawl')\n",
    "    Info_Crawl_thread = threading.Thread(target=Info_Crawl(RI,work_driver), name='Info_Crawl')\n",
    "    \n",
    "    Crawls_threads.start()\n",
    "    Institution_Crawl_thread.start()\n",
    "    Info_Crawl_thread.start()\n",
    "    \n",
    "    Info_Crawl_thread.join()\n",
    "    Institution_Crawl_thread.join()\n",
    "    Crawls_threads.join()\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "def Crawls(RI,work_driver):\n",
    "    current_metadata_total = work_driver.find_elements_by_id('current_metadata_total')\n",
    "    total = 0\n",
    "    temp_count = 0\n",
    "    if current_metadata_total!=[]:\n",
    "        total = int(current_metadata_total[0].text) \n",
    "        temp_count = total\n",
    "    \n",
    "    table = work_driver.find_elements_by_xpath('//table[@class=\"vcrNavBar\"]//tbody//tr//td[@class=\"goto\"]')\n",
    "    \n",
    "    pages = 0\n",
    "    if table!= []:\n",
    "        pages = table[1].text.replace(\" \",\"\").replace(\"Pageof\",\"\")        \n",
    "        logger.info('總共有' + str(total) + '個 publishes' + '，' + str(pages) + '個分頁')\n",
    "        for i in range(0,int(pages)):\n",
    "            logger.info(\"第\"+str(i+1)+\"分頁抓取中...\")\n",
    "            Work_Crawl(RI,work_driver,50*i)            \n",
    "            work_driver.find_element_by_xpath('//img[@title=\"Next Page\"]').click() #切換下一分頁\n",
    "            temp_count = temp_count - 50\n",
    "            if temp_count <=0 :\n",
    "                logger.info('Work_item抓取完成，'+ RI+'底下共抓取'+ str(total) +'項publishes')\n",
    "    else:\n",
    "        logger.info('Work_item抓取完成，' + RI+'底下並無任何publishes')\n",
    "#------------------------------------------------------------------------------------------\n",
    "def Work_Crawl(RI,work_driver,start):\n",
    "    try:\n",
    "        item_list=[]\n",
    "        summary_recnum_list = work_driver.find_elements_by_class_name('summary_recnum')\n",
    "        summary_data_list = work_driver.find_elements_by_class_name('summary_data')\n",
    "        summary_date_list = work_driver.find_elements_by_class_name('summary_date')\n",
    "\n",
    "        summary_recnum2_list = work_driver.find_elements_by_class_name('summary_recnum_2')\n",
    "        summary_data2_list = work_driver.find_elements_by_class_name('summary_data_2')\n",
    "        summary_date2_list = work_driver.find_elements_by_class_name('summary_date_2')\n",
    "        \n",
    "        length = len(summary_recnum_list) + len(summary_recnum2_list)\n",
    "        goal = 0\n",
    "        for i in range(0,length):  \n",
    "            index = int(i/2)\n",
    "            if i%2 == 0:\n",
    "#                 summary_recnum = summary_recnum_list[index]\n",
    "                summary_data = summary_data_list[index]\n",
    "                summary_date = summary_date_list[index]\n",
    "            else:\n",
    "#                 summary_recnum = summary_recnum2_list[index]\n",
    "                summary_data = summary_data2_list[index]\n",
    "                summary_date = summary_date2_list[index]\n",
    "                \n",
    "            goal = i+1\n",
    "            input_elements = summary_data.find_elements_by_tag_name('input')\n",
    "            data_bold = summary_data.find_elements_by_class_name('data_bold')\n",
    "#             Number = summary_recnum.text.replace(\".\",\"\") \n",
    "            Title =''\n",
    "            Authors = ''\n",
    "            Source = ''\n",
    "            DOI = ''\n",
    "            Published = ''          \n",
    "            if len(input_elements) > 2 :\n",
    "                Title = input_elements[2].get_attribute('value')\n",
    "            if len(input_elements) > 3 :\n",
    "                Authors = input_elements[3].get_attribute('value')\n",
    "            if len(input_elements) > 5 :       \n",
    "                Source = input_elements[5].get_attribute('value')\n",
    "                \n",
    "            Published_path = '//input[@name=\"artifacts[' + str(i) + '].publicationYear\"]'\n",
    "            elements_Published = work_driver.find_elements_by_xpath(Published_path)\n",
    "            if elements_Published!=[]:\n",
    "                Published = elements_Published[0].get_attribute('value')\n",
    "            \n",
    "            DOI_path = '//input[@name=\"artifacts[' + str(i) + '].doi\"]'\n",
    "            elements_DOI = work_driver.find_elements_by_xpath(DOI_path)\n",
    "            if elements_DOI!= []:\n",
    "                DOI = elements_DOI[0].get_attribute('value')              \n",
    "            \n",
    "            added = summary_date.text.replace(\"added\",\"\").replace(\" \",\"\").replace(\"\\r\",\"\").replace(\"\\n\",\"\")\n",
    "\n",
    "            work_item={}\n",
    "            work_item['RI'] = RI\n",
    "#             work_item['Number'] = Number\n",
    "            work_item['Title'] = Title\n",
    "            work_item['Authors'] = Authors\n",
    "            work_item['Source'] = Source\n",
    "            work_item['Published'] = Published\n",
    "            work_item['DOI'] = DOI\n",
    "            work_item['added'] = added\n",
    "            work_item_list.append(work_item)          \n",
    "            \n",
    "            write_excel_thread = threading.Thread(write_excel(Work_sheet,RI,Title,Authors,Source,Published,DOI,added,None))\n",
    "            write_excel_thread.start()   \n",
    "\n",
    "#             if int(total) == int(Number):\n",
    "#                 logger.info('Work_item抓取完成，'+ RI+'底下共抓取'+ str(total) +'項publishes')\n",
    "#                 break\n",
    "    except Exception as e:                \n",
    "            logger.error('第'+ str(start+goal)+'項publishes ，抓取失敗')\n",
    "            logger.error(e)\n",
    "            traceback = sys.exc_info()[2]\n",
    "            logger.error(sys.exc_info())\n",
    "            logger.error(traceback.tb_lineno)\n",
    "            logger.error(e)\n",
    "#------------------------------------------------------------------------------------------\n",
    "def Results_Search(driver):\n",
    "    namelist=[]\n",
    "    nameUrlist=[]\n",
    "    title_list = driver.find_elements_by_xpath('//td[@class=\"summary_data\"]//a')    \n",
    "    authorSetsNums = driver.find_elements_by_class_name('authorSetsNum')\n",
    "    for index, title in enumerate(title_list):                                         \n",
    "        nameUrlist.append('http://www.researcherid.com/rid/' + title.get_attribute('title'))\n",
    "        namelist.append(authorSetsNums[index].text +\" : \"+ title.text)\n",
    "\n",
    "    for index, element in enumerate(namelist):  \n",
    "        logger.info('--------------------------------------------------------------------------')\n",
    "        logger.info(\"NAME : \" + element)    \n",
    "        try :\n",
    "#             if index >6:\n",
    "            script = \"window.open('\"+ nameUrlist[index] + \"', 'new_window')\"\n",
    "            logger.info(script)\n",
    "            driver.execute_script(script)\n",
    "            driver.switch_to_window(driver.window_handles[1])\n",
    "            Work_Search(nameUrlist[index],driver)  \n",
    "            driver.switch_to_window(driver.window_handles[0])\n",
    "        except Exception as e:\n",
    "            logger.info(\"NAME : \" + element + ' Crawl Failed ' + str(e))\n",
    "            traceback = sys.exc_info()[2]\n",
    "            logger.error(sys.exc_info())\n",
    "            logger.error(traceback.tb_lineno)\n",
    "            logger.error(e)\n",
    "        logger.info(\"NAME : \" + element + ' Crawl Over')\n",
    "        logger.info('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "網頁錯誤，等候重新開啟\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-30 14:52:37 - RIS - INFO: - logger已啟動\n"
     ]
    }
   ],
   "source": [
    "#網頁開啟  \n",
    "driver = None\n",
    "while(driver == None):        \n",
    "    driver = open_web() \n",
    "    \n",
    "if logger!= None:\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    logger.info('RIS Close logger') \n",
    "    logger.info('RIS finished output') \n",
    "        \n",
    "#網頁成功開啟後開啟logger\n",
    "try:  \n",
    "    #設置logger\n",
    "    logger = logging.getLogger(\"RIS\")   #不加名稱設置root logger\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s: - %(message)s' ,\n",
    "        datefmt= '%Y-%m-%d %H:%M:%S' )\n",
    "    log_filter=logging.Filter(\"RIS\")\n",
    "\n",
    "    # 使用FileHandler輸出到文件\n",
    "    loggerPath = 'RI_CRAWL_THREAD/RIS - log - '+ str(today) +'.txt' \n",
    "    directory = os.path.dirname(loggerPath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    fh = logging.FileHandler(loggerPath)\n",
    "\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # 使用StreamHandler輸出到屏幕\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    ch.setFormatter(formatter)\n",
    "    # 添加兩個Handler\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    #Handler只啟動一次\n",
    "    #設置logger\n",
    "    logger.info('logger已啟動')\n",
    "except Exception as e:\n",
    "    traceback = sys.exc_info()[2]    \n",
    "    print('關閉logger')\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    logger.info('RIS Close logger') \n",
    "    logger.info('RIS finished output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-30 14:52:41 - RIS - INFO: - 1\n",
      "2018-03-30 14:52:41 - RIS - INFO: - 從第1頁開始查詢\n",
      "2018-03-30 14:52:41 - RIS - INFO: - 第1個Results查詢分頁\n",
      "2018-03-30 14:52:41 - RIS - INFO: - Results逐筆查詢開始...\n",
      "2018-03-30 14:52:43 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:52:43 - RIS - INFO: - NAME : 1. : Hsu Heng-Ming\n",
      "2018-03-30 14:52:43 - RIS - INFO: - window.open('http://www.researcherid.com/rid/H-7167-2012', 'new_window')\n",
      "2018-03-30 14:52:43 - RIS - INFO: - http://www.researcherid.com/rid/H-7167-2012\n",
      "2018-03-30 14:52:51 - RIS - INFO: - 總共有51個 publishes，2個分頁\n",
      "2018-03-30 14:52:51 - RIS - INFO: - 第1分頁抓取中...\n",
      "2018-03-30 14:54:31 - RIS - INFO: - 第2分頁抓取中...\n",
      "2018-03-30 14:54:55 - RIS - INFO: - Work_item抓取完成，H-7167-2012底下共抓取51項publishes\n",
      "2018-03-30 14:54:55 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:55:05 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:55:05 - RIS - INFO: - NAME : 1. : Hsu Heng-Ming Crawl Over\n",
      "2018-03-30 14:55:05 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:55:05 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:55:05 - RIS - INFO: - NAME : 2. : Huang Wenchi\n",
      "2018-03-30 14:55:05 - RIS - INFO: - window.open('http://www.researcherid.com/rid/F-3981-2010', 'new_window')\n",
      "2018-03-30 14:55:05 - RIS - INFO: - http://www.researcherid.com/rid/F-3981-2010\n",
      "2018-03-30 14:55:27 - RIS - INFO: - Work_item抓取完成，F-3981-2010底下並無任何publishes\n",
      "2018-03-30 14:55:28 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:55:38 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:55:38 - RIS - INFO: - NAME : 2. : Huang Wenchi Crawl Over\n",
      "2018-03-30 14:55:38 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:55:38 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:55:38 - RIS - INFO: - NAME : 3. : JHUANG LING-SYUAN\n",
      "2018-03-30 14:55:38 - RIS - INFO: - window.open('http://www.researcherid.com/rid/K-2967-2014', 'new_window')\n",
      "2018-03-30 14:55:38 - RIS - INFO: - http://www.researcherid.com/rid/K-2967-2014\n",
      "2018-03-30 14:55:59 - RIS - INFO: - Work_item抓取完成，K-2967-2014底下並無任何publishes\n",
      "2018-03-30 14:56:00 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:56:10 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:56:10 - RIS - INFO: - NAME : 3. : JHUANG LING-SYUAN Crawl Over\n",
      "2018-03-30 14:56:10 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:56:10 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:56:10 - RIS - INFO: - NAME : 4. : kuo tingjui\n",
      "2018-03-30 14:56:10 - RIS - INFO: - window.open('http://www.researcherid.com/rid/J-9713-2015', 'new_window')\n",
      "2018-03-30 14:56:10 - RIS - INFO: - http://www.researcherid.com/rid/J-9713-2015\n",
      "2018-03-30 14:56:40 - RIS - INFO: - Work_item抓取完成，J-9713-2015底下並無任何publishes\n",
      "2018-03-30 14:56:41 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:56:51 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:56:51 - RIS - INFO: - NAME : 4. : kuo tingjui Crawl Over\n",
      "2018-03-30 14:56:51 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:56:51 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:56:51 - RIS - INFO: - NAME : 5. : Lin Chihping\n",
      "2018-03-30 14:56:51 - RIS - INFO: - window.open('http://www.researcherid.com/rid/C-1060-2009', 'new_window')\n",
      "2018-03-30 14:56:51 - RIS - INFO: - http://www.researcherid.com/rid/C-1060-2009\n",
      "2018-03-30 14:57:12 - RIS - INFO: - Work_item抓取完成，C-1060-2009底下並無任何publishes\n",
      "2018-03-30 14:57:12 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:57:22 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:57:22 - RIS - INFO: - NAME : 5. : Lin Chihping Crawl Over\n",
      "2018-03-30 14:57:22 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:57:22 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:57:22 - RIS - INFO: - NAME : 6. : Mohamed Tamer\n",
      "2018-03-30 14:57:22 - RIS - INFO: - window.open('http://www.researcherid.com/rid/B-7085-2018', 'new_window')\n",
      "2018-03-30 14:57:23 - RIS - INFO: - http://www.researcherid.com/rid/B-7085-2018\n",
      "2018-03-30 14:57:42 - RIS - INFO: - Work_item抓取完成，B-7085-2018底下並無任何publishes\n",
      "2018-03-30 14:57:43 - RIS - INFO: - Institution_item 抓取完成\n",
      "2018-03-30 14:57:53 - RIS - INFO: - Info_item抓取完成\n",
      "2018-03-30 14:57:53 - RIS - INFO: - NAME : 6. : Mohamed Tamer Crawl Over\n",
      "2018-03-30 14:57:53 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:57:53 - RIS - INFO: - --------------------------------------------------------------------------\n",
      "2018-03-30 14:57:53 - RIS - INFO: - NAME : 7. : Wang YueLi\n",
      "2018-03-30 14:57:53 - RIS - INFO: - window.open('http://www.researcherid.com/rid/E-2450-2011', 'new_window')\n",
      "2018-03-30 14:57:53 - RIS - INFO: - http://www.researcherid.com/rid/E-2450-2011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-26a7c283e1d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"第\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"個Results查詢分頁\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results逐筆查詢開始...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mResults_Search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//img[@title=\"Next Page\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#切換下一分頁\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-10e144677603>\u001b[0m in \u001b[0;36mResults_Search\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m             \u001b[0mWork_Search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameUrlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-10e144677603>\u001b[0m in \u001b[0;36mWork_Search\u001b[1;34m(url, work_driver)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mupdate_per_data_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwork_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//select [@id=\"resultsPerPage\"]//option[@value=\"50\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_per_data_action\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mupdate_per_data_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#修改頁面上Results的顯示筆數\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0melements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[contains(@class, 'foo')]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \"\"\"\n\u001b[1;32m--> 401\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    981\u001b[0m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[0;32m    982\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             'value': value})['value'] or []\n\u001b[0m\u001b[0;32m    984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                 \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#主程式\n",
    "# start = 起始頁數\n",
    "start = 1\n",
    "maxSearchNum = 0\n",
    "#interval = 儲存頁數間隔\n",
    "interval = 20\n",
    "pages = driver.find_elements_by_xpath('//table[@class=\"vcrNavBar\"]//tbody//tr//td[@class=\"goto\"]')[1].text.replace(\" \",\"\").replace(\"Pageof\",\"\")\n",
    "for start_pages in range(start,int(pages),interval):   \n",
    "    pageNumBoxes = driver.find_element_by_class_name('pageNumBoxes')\n",
    "    pageNumBoxes.send_keys(Keys.BACK_SPACE) #清空內容\n",
    "    pageNumBoxes.send_keys(Keys.BACK_SPACE) #清空內容\n",
    "    pageNumBoxes.send_keys(Keys.BACK_SPACE) #清空內容\n",
    "    pageNumBoxes.send_keys(start_pages) #清空內容\n",
    "    driver.find_elements_by_tag_name('a')[11].click() #前往指定頁面\n",
    "        \n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    work_frame = pd.DataFrame({}, columns=['RI','Title','Authors','Source','DOI','added'])\n",
    "    work_item_list = []\n",
    "\n",
    "    Institution_frame = pd.DataFrame({}, columns=['RI','Institution','Sub-Org/Dept','Role','Start Date','End Date'])\n",
    "    Institution_item_list = []\n",
    "\n",
    "    Info_frame = pd.DataFrame({}, columns=['RI','Name','Other Names','ORCID','Email','My URLs','Keywords','Subject'])\n",
    "    Info_item_list = []\n",
    "    \n",
    "    if start_pages +interval <= int(pages) :\n",
    "        maxSearchNum = start_pages +interval       \n",
    "    else:\n",
    "        maxSearchNum = int(pages)\n",
    "        \n",
    "    file_path = 'RI_CRAWL_THREAD/' +str(start_pages) +'-' + str(maxSearchNum-1) +'/' + str(today)  + '.xlsx'        \n",
    "        \n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    workbook = xlsxwriter.Workbook(file_path)\n",
    "    #   Work_sheet\n",
    "    Work_sheet = workbook.add_worksheet('Work')\n",
    "    Work_row = 0\n",
    "    Work_col = 0\n",
    "    Work_sheet.write(Work_row, 0, 'RI')\n",
    "    Work_sheet.write(Work_row, 1, 'Title')\n",
    "    Work_sheet.write(Work_row, 2, 'Authors')\n",
    "    Work_sheet.write(Work_row, 3, 'Source')\n",
    "    Work_sheet.write(Work_row, 4, 'Published')\n",
    "    Work_sheet.write(Work_row, 5, 'DOI')\n",
    "    Work_sheet.write(Work_row, 6, 'added')\n",
    "    Work_row = 1\n",
    "\n",
    "    #   Institution_sheet\n",
    "    Institution_sheet = workbook.add_worksheet('Institution')\n",
    "    Institution_row = 0\n",
    "    Institution_col = 0\n",
    "    Institution_sheet.write(Institution_row, 0, 'RI')\n",
    "    Institution_sheet.write(Institution_row, 1, 'Primary_Institution')\n",
    "    Institution_sheet.write(Institution_row, 2, 'Joint_Affiliation')\n",
    "    Institution_sheet.write(Institution_row, 3, 'Past_Institution_Name')\n",
    "    Institution_sheet.write(Institution_row, 4, 'SubOrg_Dept')\n",
    "    Institution_sheet.write(Institution_row, 5, 'Role')\n",
    "    Institution_sheet.write(Institution_row, 6, 'Start_Date')\n",
    "    Institution_sheet.write(Institution_row, 7, 'End_Date')\n",
    "    Institution_row = 1\n",
    "\n",
    "\n",
    "    #   Info_sheet\n",
    "    Info_sheet = workbook.add_worksheet('Info')\n",
    "    Info_row = 0\n",
    "    Info_col = 0\n",
    "    Info_sheet.write(Info_row, 0, 'RI')\n",
    "    Info_sheet.write(Info_row, 1, 'Name')\n",
    "    Info_sheet.write(Info_row, 2, 'Other_Names')\n",
    "    Info_sheet.write(Info_row, 3, 'ORCID')\n",
    "    Info_sheet.write(Info_row, 4, 'Email')\n",
    "    Info_sheet.write(Info_row, 5, 'My_URLs')\n",
    "    Info_sheet.write(Info_row, 6, 'Keywords')\n",
    "    Info_sheet.write(Info_row, 7, 'Subject')\n",
    "    Info_row = 1\n",
    "    try:          \n",
    "        current_pages = driver.find_element_by_class_name('pageNumBoxes').get_attribute('value')\n",
    "        logger.info(current_pages)\n",
    "        logger.info('從第'+ str(start_pages) + '頁開始查詢')\n",
    "        for i in range(int(current_pages),maxSearchNum):  \n",
    "            logger.info(\"第\" + str(i) + \"個Results查詢分頁\") \n",
    "            logger.info(\"Results逐筆查詢開始...\")\n",
    "            Results_Search(driver)    \n",
    "            driver.find_element_by_xpath('//img[@title=\"Next Page\"]').click() #切換下一分頁\n",
    "            driver.implicitly_wait(5)\n",
    "        workbook.close()\n",
    "        logger.info('RIS Crawl finished')    \n",
    "        logger.info('--------------------------------------------------------------------------')\n",
    "#         driver.close()\n",
    "    except Exception as e:\n",
    "        logger.error(\"RIS :  Crawl Over\")\n",
    "        workbook.close()   \n",
    "        driver.switch_to_window(driver.window_handles[0])\n",
    "        traceback = sys.exc_info()[2]\n",
    "        logger.error(sys.exc_info())\n",
    "        logger.error(traceback.tb_lineno)\n",
    "        logger.error(e)    \n",
    "    finally:    \n",
    "        workbook.close()       \n",
    "    #強制輸出至EXCEL    \n",
    "    workbook.close()\n",
    "#------------------------------------------------------------------------------------------ for end    \n",
    "handlers = logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)\n",
    "logger.info('RIS Close logger') \n",
    "logger.info('RIS finished output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#強制關閉logger\n",
    "driver.switch_to_window(driver.window_handles[0])\n",
    "workbook.close()\n",
    "handlers = logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)\n",
    "logger.info('RIS Close logger') \n",
    "logger.info('RIS finished output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#強制關閉&輸出至EXCEL\n",
    "handlers = logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)\n",
    "logger.info('RIS Close logger') \n",
    "logger.info('RIS finished output') \n",
    "# workbook.close()\n",
    "driver.switch_to_window(driver.window_handles[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
